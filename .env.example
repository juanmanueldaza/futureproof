# FutureProof Configuration
# Copy this file to .env and fill in your values
# Full setup guide: docs/SOURCES.md

# =============================================================================
# LLM Providers (all have FREE tiers - no credit card required)
# The system automatically falls back between providers on rate limits.
# You only need ONE, but configure several for resilience.
# =============================================================================

# Google Gemini - Easiest to start. 1M tokens/day, 15 req/min
# Get your free key at: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=

# Groq - Fast inference, 100k tokens/day per model
# Get your free key at: https://console.groq.com/keys
GROQ_API_KEY=

# Cerebras - Extremely fast inference, free tier
# Get your free key at: https://cloud.cerebras.ai/
CEREBRAS_API_KEY=

# SambaNova - Free tier with Llama 405B (largest free model!)
# Get your free key at: https://cloud.sambanova.ai/apis
SAMBANOVA_API_KEY=

# Azure OpenAI / AI Foundry ($200 free credits, requires credit card)
# Sign up at: https://ai.azure.com/
# Deploy models in AI Foundry, then copy key + endpoint
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-12-01-preview
AZURE_CHAT_DEPLOYMENT=gpt-4.1
AZURE_EMBEDDING_DEPLOYMENT=text-embedding-3-small

# =============================================================================
# Data Gathering Configuration
# =============================================================================

# GitHub username for data gathering
GITHUB_USERNAME=your_github_username

# GitLab username for data gathering
GITLAB_USERNAME=your_gitlab_username

# GitLab groups to include (comma-separated)
# GITLAB_GROUPS=group1,group2

# Portfolio URL to scrape
PORTFOLIO_URL=https://your-portfolio.com

# Default language for CV generation (en or es)
DEFAULT_LANGUAGE=en

# =============================================================================
# MCP (Model Context Protocol) Configuration - Optional
# When configured, enables real-time data access instead of CLI-based gathering
# =============================================================================

# GitHub MCP Server
# Create token at: https://github.com/settings/tokens
# Required scopes: repo, read:user, user:email
GITHUB_PERSONAL_ACCESS_TOKEN=

# Set to false to use native binary instead of Docker
# GITHUB_MCP_USE_DOCKER=true
# GITHUB_MCP_IMAGE=ghcr.io/github/github-mcp-server

# GitLab MCP Server
# Create token at: https://gitlab.com/-/user_settings/personal_access_tokens
# Required scopes: api, read_user
GITLAB_MCP_URL=
GITLAB_MCP_TOKEN=

# =============================================================================
# Market Intelligence Configuration - Optional
# Most sources require NO configuration (JobSpy, HN, RemoteOK, etc.)
# =============================================================================

# Tavily Search API Key (for salary data and market research)
# Get your free key at: https://tavily.com/ (1,000 queries/month, no credit card)
TAVILY_API_KEY=

# Disable specific sources if needed (all enabled by default)
# JOBSPY_ENABLED=true
# HN_MCP_ENABLED=true

# Cache durations (hours)
# MARKET_CACHE_HOURS=24
# JOB_CACHE_HOURS=12
# CONTENT_CACHE_HOURS=12

# =============================================================================
# Knowledge Base Configuration - Optional
# =============================================================================

# Auto-index career data after gathering (default: true)
KNOWLEDGE_AUTO_INDEX=true

# Chunking settings for RAG
KNOWLEDGE_CHUNK_MAX_TOKENS=500
KNOWLEDGE_CHUNK_MIN_TOKENS=50

# =============================================================================
# LLM Settings - Optional
# =============================================================================

# LLM_PROVIDER=gemini          # Default provider (gemini, groq, azure)
# LLM_MODEL=                   # Override model name (empty = provider default)
# LLM_TEMPERATURE=0.3          # General temperature (0.0-1.0)
# CV_TEMPERATURE=0.2           # CV generation temperature (lower = more consistent)
